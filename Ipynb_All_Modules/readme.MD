# ğŸ¥ Databricks Lakehouse ML Project â€“ End-to-End Readmission Prediction

This repository contains an **end-to-end Databricks Lakehouse project** that demonstrates how to design, build, and operationalize a **real-world analytics + machine learning solution** for **hospital readmission prediction**.

The project follows a **modern Lakehouse architecture** and has been **enhanced to support future predictions (risk scoring)**, making it suitable for **proactive decision-making**, not just historical analysis.

```
Configuration â†’ Bronze â†’ Silver â†’ Gold â†’ ML Model (Training + Future Scoring) â†’ Dashboards (Historical + Predictive)
```

---

## ğŸ“‚ Repository Structure

| Notebook                     | Purpose                                                  |
| ---------------------------- | -------------------------------------------------------- |
| `1. Configuration.ipynb`     | Environment setup and shared configurations              |
| `2. Bronze.ipynb`            | Raw data ingestion layer                                 |
| `3. Silver.ipynb`            | Cleaned and validated data layer                         |
| `4. Gold.ipynb`              | Business aggregates & ML-ready datasets                  |
| `5. ML Model.ipynb`          | Model training, evaluation **and future risk scoring**   |
| `6. Dashboard Queries.ipynb` | SQL analytics for **historical + predictive dashboards** |

---

## 1ï¸âƒ£ Configuration Notebook

### ğŸ¯ Objective

Provide a **centralized configuration layer** for catalogs, schemas, and reusable variables across the project.

### ğŸ”‘ Key Responsibilities

* Select catalog and schema
* Define table names and reusable paths
* Validate execution context

### âœ… Outcome

Consistent execution environment across all layers.

---

## 2ï¸âƒ£ Bronze Layer â€“ Raw Ingestion

### ğŸ¯ Objective

Ingest raw source data into the Lakehouse **without altering business meaning**.

### ğŸ”‘ Key Responsibilities

* Read raw source data
* Append ingestion metadata
* Write Delta tables
* Maintain auditability

### ğŸ§  Design Principle

> Bronze data is raw, immutable, and replayable.

---

## 3ï¸âƒ£ Silver Layer â€“ Data Cleaning & Validation

### ğŸ¯ Objective

Prepare **high-quality, trusted datasets** for analytics and machine learning.

### ğŸ”‘ Key Responsibilities

* Data type standardization
* Null handling and validation
* Deduplication
* Business rule enforcement
* Feature-ready transformations

### ğŸ§  Design Principle

> Silver data represents the analytical source of truth.

---

## 4ï¸âƒ£ Gold Layer â€“ Business & ML-Ready Data

### ğŸ¯ Objective

Create **consumption-ready datasets** for reporting and ML.

### ğŸ”‘ Key Responsibilities

* Business aggregations
* Metric calculations
* ML-friendly feature tables
* Optimized schemas for performance

### ğŸ§  Design Principle

> Gold data directly answers business questions.

---

## 5ï¸âƒ£ ML Model Notebook â€“ Training & Future Risk Prediction (Updated)

### ğŸ¯ Objective

Build, evaluate, and **apply machine learning models to both historical and future data**.

### ğŸ”‘ Key Responsibilities

* Feature engineering using Spark ML Pipelines
* Train/Test split
* Model training (Random Forest, Gradient Boosted Trees)
* Model evaluation using AUC, accuracy, precision, recall
* MLflow experiment tracking
* **Risk score inference using prediction probabilities**
* **Scoring future/unseen records**

### ğŸ§  Key Enhancements

* Extracted `risk_score` from model probability (`P(label = 1)`)
* Categorized risk levels (High / Medium / Low)
* Persisted prediction outputs as Gold tables

### âœ… Outcome

A **production-ready predictive model** capable of scoring new patient encounters and generating actionable risk insights.

---

## 6ï¸âƒ£ Dashboard Queries â€“ Historical & Predictive Insights (Updated)

### ğŸ¯ Objective

Expose **both historical metrics and future ML predictions** through SQL analytics and dashboards.

### ğŸ”‘ Key Responsibilities

* Historical KPIs (readmission trends, volumes)
* Predictive KPIs (risk score distributions)
* High-risk patient identification
* SQL queries for dashboards
* Support filters and drill-downs

### ğŸ§  Example Predictive Insights

* Top high-risk patients
* Risk distribution by admission type
* Predicted vs actual readmissions
* Risk trends over time

### âœ… Outcome

Dashboards that support **proactive clinical and operational decision-making**.

---

## ğŸ§  End-to-End Architecture Summary

```
Raw Data
   â†“
Bronze (Raw Delta)
   â†“
Silver (Cleaned & Validated)
   â†“
Gold (Aggregates & ML Features)
   â†“
ML Models (Training + Risk Scoring)
   â†“
Dashboards (Historical + Predictive)
```

---

## ğŸš€ How Machine Learning Enhances This Project

* Moves analytics from descriptive â†’ predictive
* Identifies high-risk patients before readmission occurs
* Generates probabilistic risk scores instead of binary outcomes
* Enables prioritization and early intervention
* Integrates seamlessly with Lakehouse architecture

---

## ğŸ“Œ Key Skills Demonstrated

* Databricks Lakehouse Architecture
* Delta Lake & Spark SQL
* PySpark Data Engineering
* Spark ML Pipelines
* MLflow experiment tracking
* Predictive analytics & risk scoring
* SQL dashboards with ML insights

---

## âœ¨ Final Notes

This project now represents a **full decision intelligence system**:

* Historical reporting
* Predictive modeling
* Risk-based insights
* Dashboard-driven consumption

---

âœ¨ *Built with Databricks, Spark, Delta Lake, MLflow, and SQL Analytics*
