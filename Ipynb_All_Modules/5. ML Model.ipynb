{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "580c0d52-37e7-4fee-95d8-d7ee737bb153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#NOTEBOOK 5/6: ML MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a728c240-29aa-4e9a-8302-2aac7e155ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. FIXING THE SCHEMA AND IMPORTING ML FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054690b8-cacc-4ecf-a47d-b6999742cdc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selecting ML features schema and healthcare_analytics catalog\n",
    "spark.sql(\"USE CATALOG healthcare_analytics\")\n",
    "spark.sql(\"USE SCHEMA ml_features\")\n",
    "spark.sql(\"SELECT current_catalog(), current_schema()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efab22c2-3b85-4422-90cd-f01e4ee64b3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries and functions\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fcf14a3-9132-4aea-8e00-1b39edc5bf25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. SELECTING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2939d091-d93d-4eb0-b66d-8b430391e4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Numeric features\n",
    "numeric_features = [\n",
    "    \"time_in_hospital\",\n",
    "    \"num_lab_procedures\",\n",
    "    \"num_procedures\",\n",
    "    \"num_medications\",\n",
    "    \"number_outpatient\",\n",
    "    \"number_emergency\",\n",
    "    \"number_inpatient\",\n",
    "    \"number_diagnoses\",\n",
    "    \"total_procedures\",\n",
    "    \"is_emergency\"\n",
    "]\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = [\n",
    "    \"age_group\",\n",
    "    \"admission_type_id\",\n",
    "    \"medical_specialty\",\n",
    "    \"num_medications_category\"\n",
    "]\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27f3526f-c8a2-45cd-a488-7436d54828d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. PREPARE DATA FOR ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1265f775-fd6d-45da-a76d-808cf0d186af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# READ SILVER DATA\n",
    "\n",
    "df = spark.table(\"healthcare_analytics.silver.silver_events\")\n",
    "print(f\"Total records: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeaad0c3-f6ac-4b98-bb26-d9a367fac22e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769697272118}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select columns and rename target\n",
    "\n",
    "ml_df = df.select(\n",
    "    [\"encounter_id\", \"patient_nbr\"] + \n",
    "    numeric_features + \n",
    "    categorical_features + \n",
    "    [\"readmitted_30days\"]\n",
    ").withColumnRenamed(\"readmitted_30days\", \"label\")\n",
    "\n",
    "#In ML:\n",
    "#Features → input variables (X)\n",
    "#Label → output variable (y) we want to predict\n",
    "\n",
    "# Show sample\n",
    "display(ml_df.limit(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4959b24-4a76-45ad-8181-8c5177611647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##4. CREATE FEATURE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f8e71ac-d440-415c-a5ad-64f80e276ccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# String indexing for categorical features\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\")\n",
    "    for col in categorical_features\n",
    "]\n",
    "\n",
    "# One-hot encoding Emergency (0) < Urgent (1) < Elective (2) \n",
    "# Converts category index into binary vector [1,0,0] for Emergency, [0,1,0] for Urgent, [0,0,1] for Elective\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_encoded\")\n",
    "    for col in categorical_features\n",
    "]\n",
    "\n",
    "# Combine all features\n",
    "encoded_cols = [f\"{col}_encoded\" for col in categorical_features]\n",
    "all_features = numeric_features + encoded_cols\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=all_features,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Create pipeline instead of manually running:Indexing, Encoding, Assembling\n",
    "feature_pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "# Transform data\n",
    "print(\"Creating features...\")\n",
    "feature_model = feature_pipeline.fit(ml_df) #Fit = learn structure\n",
    "ml_transformed = feature_model.transform(ml_df) #Transform = apply structure\n",
    "\n",
    "# Select final columns\n",
    "ml_features_df = ml_transformed.select(\"encounter_id\", \"patient_nbr\", \"features\", \"label\")\n",
    "\n",
    "print(f\"Features created: {ml_features_df.count()} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b725b1a9-75b1-4baf-97c5-de552a9d3408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing to ml_features table\n",
    "ml_features_table = \"healthcare_analytics.ml_features.readmission_features\"\n",
    "\n",
    "ml_features_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(ml_features_table)\n",
    "\n",
    "print(\"Features saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea04ed64-29d6-4efd-8567-07b11b5e6313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5. TRAIN-TEST DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe56c2d2-7e1c-4ead-8671-8bf4f1620991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split 80-20 data for training and testing respectively\n",
    "\n",
    "train_df, test_df = ml_features_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training: {train_df.count()} records\")\n",
    "print(f\"Test: {test_df.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ce37d5-0e65-41d2-94b4-efe50579ce4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##6. CREATING RANDOM FOREST AND GRADIENT BOOST TREES MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c173170-c5ed-439c-a1d7-3097330d0a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Random Forest...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_Model\"):\n",
    "    \n",
    "    # Create model\n",
    "    rf = RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        numTrees=100,\n",
    "        maxDepth=10,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    rf_model = rf.fit(train_df)\n",
    "    \n",
    "    # Predict\n",
    "    rf_predictions = rf_model.transform(test_df)\n",
    "    \n",
    "    # Evaluate\n",
    "    evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "    \n",
    "    auc_rf = evaluator_auc.evaluate(rf_predictions)\n",
    "    acc_rf = evaluator_acc.evaluate(rf_predictions)\n",
    "    \n",
    "    print(f\"Random Forest - AUC: {auc_rf:.4f}, Accuracy: {acc_rf:.4f}\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"auc\", auc_rf)\n",
    "    mlflow.log_metric(\"accuracy\", acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86b944c4-3ca5-4cce-9533-5695b9c9f566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees Model\n",
    "print(\"Training Gradient Boosted Trees...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"GBT_Model\"):\n",
    "    \n",
    "    # Create model\n",
    "    gbt = GBTClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        maxIter=50,\n",
    "        maxDepth=8,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    gbt_model = gbt.fit(train_df)\n",
    "    \n",
    "    # Predict\n",
    "    gbt_predictions = gbt_model.transform(test_df)\n",
    "    \n",
    "    # Evaluate\n",
    "    auc_gbt = evaluator_auc.evaluate(gbt_predictions)\n",
    "    acc_gbt = evaluator_acc.evaluate(gbt_predictions)\n",
    "    \n",
    "    print(f\"GBT - AUC: {auc_gbt:.4f}, Accuracy: {acc_gbt:.4f}\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"auc\", auc_gbt)\n",
    "    mlflow.log_metric(\"accuracy\", acc_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6c7400a-dfca-4c7d-9311-9e0d6dfb5ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##7. COMPARING AND CHOOSING THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e26a6b4b-1c3a-494b-945d-91e8eee219f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Random Forest  - AUC: {auc_rf:.4f}, Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"GBT            - AUC: {auc_gbt:.4f}, Accuracy: {acc_gbt:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "best_auc = auc_rf if auc_rf >= auc_gbt else auc_gbt\n",
    "\n",
    "\n",
    "if auc_gbt > auc_rf:\n",
    "    print(\"Best Model: Gradient Boosted Trees\")\n",
    "else:\n",
    "    print(\"Best Model: Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27dc10e4-4382-4e1f-bea3-965902e35d8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##8. SHOWING SAMPLE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cb6af55-1250-44f0-ab5f-eee76f82cc66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show predictions from best model (using GBT)\n",
    "\n",
    "sample_predictions = gbt_predictions.select(\n",
    "    \"encounter_id\",\n",
    "    \"patient_nbr\",\n",
    "    col(\"label\").alias(\"actual\"),\n",
    "    col(\"prediction\").alias(\"predicted\")\n",
    ").limit(20)\n",
    "\n",
    "display(sample_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "808dbfdf-ba13-4abf-85b3-9cb7cba6fcdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##9. CALCULATING CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fa22dc9-06b1-4874-9183-c3d75924fb90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "\n",
    "predictions_pd = gbt_predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(predictions_pd['label'], predictions_pd['prediction'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"                  Predicted: 0    Predicted: 1\")\n",
    "print(f\"Actual: 0         {cm[0,0]:<15} {cm[0,1]:<15}\")\n",
    "print(f\"Actual: 1         {cm[1,0]:<15} {cm[1,1]:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5cac485-efbb-48ab-87a1-b3d542189746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##10. FINAL INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9198e9a-9c14-40d9-87c4-75cad84a9a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ML MODEL TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Features created: {len(all_features)}\")\n",
    "print(f\"Models trained: 2 (Random Forest, GBT)\")\n",
    "print(f\"Best AUC: {best_auc:.4f}\")\n",
    "print(f\"MLflow experiments logged\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0918355-6f1d-47df-a513-d1bc413f1ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##11. GENERATE ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c54f884c-bea2-4099-a4e5-5f746c6a4827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions with probabilities from GBT model\n",
    "gbt_pred_pd = gbt_predictions.select(\"label\", \"probability\").toPandas()\n",
    "\n",
    "# Extract probability of class 1 (readmitted)\n",
    "y_true = gbt_pred_pd['label']\n",
    "y_scores = np.array([float(p[1]) for p in gbt_pred_pd['probability']])\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curve - Hospital Readmission Prediction (GBT Model)', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Display in notebook (Databricks will render it)\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Log to MLflow (this works!)\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"GBT_Model_Visualizations\"):\n",
    "    # Create the figure again for MLflow\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title('ROC Curve - Hospital Readmission Prediction (GBT Model)', fontsize=16, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_figure(fig, \"roc_curve.png\")\n",
    "    plt.close()\n",
    "    \n",
    "print(\"ROC Curve logged to MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0238ca19-e40f-4068-b3ac-6900f90781eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##12. GENERATE CONFUSION MATRIX HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f571f052-ff03-4b65-8a3a-e9daab4697f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions\n",
    "predictions_pd = gbt_predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(predictions_pd['label'], predictions_pd['prediction'])\n",
    "\n",
    "# Calculate percentages\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['Not Readmitted', 'Readmitted'])\n",
    "disp.plot(cmap='Blues', ax=ax, colorbar=True, values_format='d')\n",
    "\n",
    "# Add percentages as annotations\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i + 0.15, f'({cm_percent[i, j]:.1f}%)', \n",
    "                ha='center', va='center', color='red', fontsize=11)\n",
    "\n",
    "ax.set_title('Confusion Matrix - GBT Model\\nHospital Readmission Prediction', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"GBT_Model_Visualizations\", nested=True):\n",
    "    # Recreate figure for MLflow\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                   display_labels=['Not Readmitted', 'Readmitted'])\n",
    "    disp.plot(cmap='Blues', ax=ax, colorbar=True, values_format='d')\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i + 0.15, f'({cm_percent[i, j]:.1f}%)', \n",
    "                    ha='center', va='center', color='red', fontsize=11)\n",
    "    \n",
    "    ax.set_title('Confusion Matrix - GBT Model', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    mlflow.log_figure(fig, \"confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Confusion Matrix logged to MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fd398d-4d25-43f4-94a1-1677596f7e44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##14. FEATURE IMPORTANCE VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b42a2c9-0d07-4fa0-95b5-993af5df98fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importance from GBT model\n",
    "feature_importance = gbt_model.featureImportances.toArray()\n",
    "\n",
    "# Create feature names (only numeric features for clarity)\n",
    "feature_names = numeric_features.copy()\n",
    "\n",
    "# Create DataFrame with only the numeric features\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance[:len(numeric_features)]\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue')\n",
    "\n",
    "# Highlight top 3 features\n",
    "num_bars = len(bars)\n",
    "top_n = 3 if num_bars >= 3 else num_bars\n",
    "\n",
    "for i in range(top_n):\n",
    "    bars[i].set_color('#e74c3c')\n",
    "\n",
    "plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
    "plt.title('Top Features Predicting Hospital Readmission (GBT Model)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(importance_df['Importance']):\n",
    "    plt.text(v, i, f' {v:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"Feature_Importance\", nested=True):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue')\n",
    "    \n",
    "    # Highlight top 3\n",
    "    num_bars = len(bars)\n",
    "    top_n = 3 if num_bars >= 3 else num_bars\n",
    "    \n",
    "    for i in range(top_n):\n",
    "        bars[i].set_color('#e74c3c')\n",
    "    \n",
    "    plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
    "    plt.title('Top Features Predicting Hospital Readmission', fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(importance_df['Importance']):\n",
    "        plt.text(v, i, f' {v:.4f}', va='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(fig, \"feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Feature Importance logged to MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16e98a9f-3fd4-45c1-9c2e-c2dcb5bb6916",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##15. FUTURE READMISSION RISK PREDICTION SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331f04a0-89f5-4c31-a252-8c4ed2e05f3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Prediction Function for New Patients\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "# Function to extract probability of readmission (class 1)\n",
    "def get_readmission_probability(probability_vector):\n",
    "    \"\"\"Extract probability that patient will be readmitted\"\"\"\n",
    "    return float(probability_vector[1])\n",
    "\n",
    "# Register as UDF\n",
    "probability_udf = udf(get_readmission_probability, DoubleType())\n",
    "\n",
    "\n",
    "#Generate Risk Scores for ALL Patients\n",
    "\n",
    "\n",
    "# Use GBT model to score ALL patients in silver table\n",
    "all_predictions = gbt_model.transform(ml_features_df)\n",
    "\n",
    "# Extract risk scores\n",
    "risk_scores_df = all_predictions.select(\n",
    "    \"encounter_id\",\n",
    "    \"patient_nbr\",\n",
    "    col(\"label\").alias(\"actual_readmitted\"),\n",
    "    col(\"prediction\").alias(\"predicted_readmitted\"),\n",
    "    probability_udf(col(\"probability\")).alias(\"readmission_risk_score\")\n",
    ")\n",
    "\n",
    "# Add risk category based on probability\n",
    "risk_scores_df = risk_scores_df.withColumn(\n",
    "    \"risk_category\",\n",
    "    when(col(\"readmission_risk_score\") >= 0.7, \"VERY HIGH RISK\")\n",
    "    .when(col(\"readmission_risk_score\") >= 0.5, \"HIGH RISK\")\n",
    "    .when(col(\"readmission_risk_score\") >= 0.3, \"MEDIUM RISK\")\n",
    "    .otherwise(\"LOW RISK\")\n",
    ")\n",
    "\n",
    "# Show sample\n",
    "print(\"Sample Risk Scores:\")\n",
    "display(risk_scores_df.orderBy(col(\"readmission_risk_score\").desc()).limit(20))\n",
    "\n",
    "\n",
    "# Identify Top 100 Patients at Risk for NEXT Admission\n",
    "\n",
    "\n",
    "# Get patients who HAVEN'T been readmitted yet but are at high risk\n",
    "high_risk_future = risk_scores_df.filter(\n",
    "    (col(\"actual_readmitted\") == 0) &  # Not yet readmitted\n",
    "    (col(\"readmission_risk_score\") >= 0.5)  # But high predicted risk\n",
    ").orderBy(col(\"readmission_risk_score\").desc())\n",
    "\n",
    "print(f\"Patients at risk for FUTURE readmission: {high_risk_future.count()}\")\n",
    "print(\"\\nTop 100 patients needing preventive intervention:\")\n",
    "display(high_risk_future.limit(100))\n",
    "\n",
    "\n",
    "\n",
    "# Join with Patient Details for Actionable Insights\n",
    "\n",
    "\n",
    "# Join with silver table to get full patient context\n",
    "silver_df = spark.table(\"healthcare_analytics.silver.silver_events\")\n",
    "\n",
    "actionable_df = high_risk_future.join(\n",
    "    silver_df.select(\n",
    "        \"encounter_id\",\n",
    "        \"patient_nbr\",\n",
    "        \"age_group\",\n",
    "        \"num_medications\",\n",
    "        \"number_diagnoses\",\n",
    "        \"time_in_hospital\",\n",
    "        \"medical_specialty\",\n",
    "        \"is_emergency\",\n",
    "        \"num_medications_category\"\n",
    "    ),\n",
    "    on=[\"encounter_id\", \"patient_nbr\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Add recommended actions\n",
    "actionable_df = actionable_df.withColumn(\n",
    "    \"recommended_action\",\n",
    "    when(col(\"readmission_risk_score\") >= 0.7, \"URGENT: Schedule follow-up within 48 hours\")\n",
    "    .when(col(\"readmission_risk_score\") >= 0.6, \"Schedule follow-up within 7 days\")\n",
    "    .when(col(\"readmission_risk_score\") >= 0.5, \"Monitor closely, call within 14 days\")\n",
    "    .otherwise(\"Standard discharge protocol\")\n",
    ")\n",
    "\n",
    "print(\"Actionable Patient List with Recommendations:\")\n",
    "display(actionable_df.select(\n",
    "    \"patient_nbr\",\n",
    "    \"readmission_risk_score\",\n",
    "    \"risk_category\",\n",
    "    \"age_group\",\n",
    "    \"num_medications\",\n",
    "    \"number_diagnoses\",\n",
    "    \"medical_specialty\",\n",
    "    \"recommended_action\"\n",
    ").orderBy(col(\"readmission_risk_score\").desc()).limit(50))\n",
    "\n",
    "\n",
    "# Save to Gold Layer for Care Coordination Team\n",
    "\n",
    "\n",
    "\n",
    "# Save high-risk future patients to gold table\n",
    "future_risk_table = \"healthcare_analytics.gold.future_readmission_risk\"\n",
    "\n",
    "actionable_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(future_risk_table)\n",
    "\n",
    "print(f\"Future readmission risk table created: {future_risk_table}\")\n",
    "print(f\"   Records: {actionable_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd02827-0f5d-4d44-94c0-37b59eb4cd92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Risk Score Distribution Analysis\n",
    "\n",
    "# Analyze risk distribution\n",
    "risk_distribution = risk_scores_df.groupBy(\"risk_category\").agg(\n",
    "    count(\"*\").alias(\"patient_count\"),\n",
    "    avg(\"readmission_risk_score\").alias(\"avg_risk_score\"),\n",
    "    sum(when(col(\"actual_readmitted\") == 1, 1).otherwise(0)).alias(\"actual_readmissions\")\n",
    ").orderBy(\"avg_risk_score\", ascending=False)\n",
    "\n",
    "print(\"Risk Category Distribution:\")\n",
    "display(risk_distribution)\n",
    "\n",
    "\n",
    "# Visualize risk distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "risk_dist_pd = risk_distribution.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Patient count by risk category\n",
    "colors = ['#d73027', '#fc8d59', '#fee090', '#91bfdb']\n",
    "ax1.bar(risk_dist_pd['risk_category'], risk_dist_pd['patient_count'], color=colors)\n",
    "ax1.set_ylabel('Number of Patients', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Patient Distribution by Risk Category', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Risk Category', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(risk_dist_pd['patient_count']):\n",
    "    ax1.text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Actual readmissions by predicted risk\n",
    "ax2.bar(risk_dist_pd['risk_category'], risk_dist_pd['actual_readmissions'], color=colors)\n",
    "ax2.set_ylabel('Actual Readmissions', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Model Validation: Actual Readmissions by Risk Category', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Risk Category', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(risk_dist_pd['actual_readmissions']):\n",
    "    ax2.text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "fig.suptitle('Readmission Risk Assessment - Future Prediction System', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"Risk_Distribution_Analysis\"):\n",
    "    # Recreate figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    colors = ['#d73027', '#fc8d59', '#fee090', '#91bfdb']\n",
    "    ax1.bar(risk_dist_pd['risk_category'], risk_dist_pd['patient_count'], color=colors)\n",
    "    ax1.set_ylabel('Number of Patients', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Patient Distribution by Risk Category', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Risk Category', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(risk_dist_pd['patient_count']):\n",
    "        ax1.text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax2.bar(risk_dist_pd['risk_category'], risk_dist_pd['actual_readmissions'], color=colors)\n",
    "    ax2.set_ylabel('Actual Readmissions', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Actual Readmissions by Risk Category', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Risk Category', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(risk_dist_pd['actual_readmissions']):\n",
    "        ax2.text(i, v, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    fig.suptitle('Risk Assessment Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    mlflow.log_figure(fig, \"risk_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Risk distribution logged to MLflow!\")\n",
    "\n",
    "\n",
    "# Summary Statistics\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FUTURE READMISSION RISK PREDICTION SYSTEM - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_patients = risk_scores_df.count()\n",
    "high_risk_count = risk_scores_df.filter(col(\"readmission_risk_score\") >= 0.5).count()\n",
    "very_high_risk = risk_scores_df.filter(col(\"readmission_risk_score\") >= 0.7).count()\n",
    "\n",
    "print(f\"Total patients scored: {total_patients:,}\")\n",
    "print(f\"High risk (≥50% probability): {high_risk_count:,} ({high_risk_count/total_patients*100:.1f}%)\")\n",
    "print(f\"Very high risk (≥70% probability): {very_high_risk:,} ({very_high_risk/total_patients*100:.1f}%)\")\n",
    "print()\n",
    "print(\"Actionable Outputs:\")\n",
    "print(f\"Gold table created: {future_risk_table}\")\n",
    "print(f\"Top 100 high-risk patients identified\")\n",
    "print(f\"Recommended actions assigned\")\n",
    "print(f\"Care coordination list ready\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5. ML Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}